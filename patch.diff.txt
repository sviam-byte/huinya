diff --git a/huinya-main/app.py b/app.py
similarity index 62%
rename from huinya-main/app.py
rename to app.py
index 3a4b0f1..f2d6d4d 100644
--- a/huinya-main/app.py
+++ b/app.py
@@ -1,149 +1,224 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 
-"""Minimal Streamlit facade for BigMasterTool."""
+"""
+Streamlit demo (lightweight).
+
+Важно: не импортируем тяжёлый tool.py на уровне модуля, иначе Streamlit Cloud падает на cold start.
+Полный отчёт (тяжёлый Excel) — только через CLI локально: python cli.py <input_file>
+"""
 
 from __future__ import annotations
 
 import os
 import tempfile
-from typing import List
+from typing import List, Optional
 
 import streamlit as st
 
-from tool import (
-    BigMasterTool,
-    EXPERIMENTAL_METHODS,
-    PYINFORM_AVAILABLE,
-    STABLE_METHODS,
-    compute_connectivity_variant,
-    configure_warnings,
-    method_mapping,
-    plot_connectome,
-    plot_heatmap,
-)
-
-
-def _resolve_selected_methods(selected: List[str]) -> List[str]:
-    """Оставляет только методы, которые реально доступны в mapping."""
-    return [m for m in selected if m in method_mapping]
+def _lazy_import_tool():
+    """
+    Ленивая загрузка тяжёлого tool.py.
+    Возвращает модуль tool.
+    """
+    import tool  # noqa: F401
+    return tool
 
 
 def main() -> None:
     """Запускает Streamlit UI."""
     st.set_page_config(page_title="Time Series Connectivity Demo", layout="wide")
     st.title("Time Series Connectivity Demo")
-    st.caption("Загрузите файл и получите базовый отчёт по связям.")
+    st.caption("Онлайн-демо: быстрые heatmap/connectome. Полный Excel-отчёт — через CLI локально.")
 
-    configure_warnings(quiet=False)
+    # Никаких тяжёлых импортов до нажатия кнопки Run.
 
     uploaded_file = st.file_uploader("Upload CSV/XLSX", type=["csv", "xlsx"])
     col1, col2, col3 = st.columns(3)
     with col1:
         lag = st.number_input("Lag", min_value=1, max_value=50, value=1, step=1)
     with col2:
         threshold = st.number_input(
             "Threshold",
             min_value=0.0,
             max_value=1.0,
             value=0.2,
             step=0.05,
         )
     with col3:
         normalize = st.checkbox("normalize", value=True)
 
     col4, col5, col6 = st.columns(3)
     with col4:
         remove_outliers = st.checkbox("outliers", value=True)
     with col5:
         log_transform = st.checkbox("log", value=False)
     with col6:
         quiet_warnings = st.checkbox("quiet warnings", value=False)
 
-    if not PYINFORM_AVAILABLE:
-        st.info("TE-методы скрыты: установите pyinform для transfer entropy.")
+    # Параметры демо: ограничиваем нагрузку по умолчанию
+    st.markdown(
+        """
+**Примечание по деплою:** Streamlit Cloud не любит тяжёлые cold start и гигантский Excel с картинками.
+Здесь — интерактивный просмотр. Полный отчёт (с кучей листов и изображений) запускай локально через `cli.py`.
+        """.strip()
+    )
 
-    method_options = STABLE_METHODS + EXPERIMENTAL_METHODS
-    selected_methods = st.multiselect(
-        "Methods",
-        options=method_options,
-        default=STABLE_METHODS,
-    )
+    # Показ методов только после ленивого импорта, но без выполнения тяжёлых вещей
+    tool_mod = _lazy_import_tool()
+    tool_mod.configure_warnings(quiet=quiet_warnings)
 
-    if any(method in EXPERIMENTAL_METHODS for method in selected_methods):
-        st.warning("Часть выбранных методов помечена как experimental.")
+    if not tool_mod.PYINFORM_AVAILABLE:
+        st.info("TE-методы скрыты: установи `pyinform`, если хочешь transfer entropy (локально).")
 
-    if st.button("Run", type="primary"):
+    method_options = tool_mod.STABLE_METHODS + tool_mod.EXPERIMENTAL_METHODS
+    default_methods = tool_mod.STABLE_METHODS
+    selected_methods = st.multiselect("Methods", options=method_options, default=default_methods)
+
+    if any(m in tool_mod.EXPERIMENTAL_METHODS for m in selected_methods):
+        st.warning("Часть методов experimental: в облаке может быть медленно/нестабильно.")
+
+    run_clicked = st.button("Run", type="primary")
+    if run_clicked:
         if not uploaded_file:
             st.error("Сначала загрузите файл CSV/XLSX.")
             return
 
-        configure_warnings(quiet=quiet_warnings)
         suffix = os.path.splitext(uploaded_file.name)[1] or ".csv"
         with tempfile.TemporaryDirectory() as tmp_dir:
             input_path = os.path.join(tmp_dir, f"input{suffix}")
-            output_path = os.path.join(tmp_dir, "AllMethods_Full.xlsx")
 
             with open(input_path, "wb") as f:
                 f.write(uploaded_file.getbuffer())
 
-            tool = BigMasterTool(enable_experimental=False)
-            tool.lag_ranges = {v: range(1, lag + 1) for v in method_mapping}
+            # Лёгкий режим: считаем только то, что нужно для визуализации выбранных методов
+            engine = tool_mod.BigMasterTool(enable_experimental=False)
+            engine.lag_ranges = {v: range(1, lag + 1) for v in tool_mod.method_mapping}
 
             with st.spinner("Обработка данных..."):
-                tool.load_data_excel(
+                engine.load_data_excel(
                     input_path,
                     log_transform=log_transform,
                     remove_outliers=remove_outliers,
                     normalize=normalize,
                     fill_missing=True,
                     check_stationarity=False,
                 )
-                tool.run_all_methods()
-                tool.export_big_excel(
-                    output_path,
-                    threshold=threshold,
-                    window_size=100,
-                    overlap=50,
-                    log_transform=log_transform,
-                    remove_outliers=remove_outliers,
-                    normalize=normalize,
-                    fill_missing=True,
-                    check_stationarity=False,
-                )
+                # В облаке НЕ делаем полный export_big_excel — он слишком тяжёлый.
+                engine.run_all_methods()
 
-            resolved_methods = _resolve_selected_methods(selected_methods)
+            resolved_methods = [m for m in selected_methods if m in tool_mod.method_mapping]
             if not resolved_methods:
                 st.info("Методы не выбраны или недоступны.")
                 return
 
             st.subheader("Heatmaps")
-            for method in resolved_methods[:2]:
-                matrix = compute_connectivity_variant(
-                    tool.data_normalized,
-                    method,
-                    lag=lag,
-                )
-                heatmap = plot_heatmap(
-                    matrix,
-                    f"{method} Heatmap",
-                    legend_text=f"Lag={lag}",
-                )
-                st.image(heatmap, caption=method)
+            # Ограничим число картинок, чтобы UI не умирал
+            max_show = min(3, len(resolved_methods))
+            for method in resolved_methods[:max_show]:
+                with st.spinner(f"Heatmap: {method}"):
+                    matrix = tool_mod.compute_connectivity_variant(engine.data_normalized, method, lag=lag)
+                    heatmap = tool_mod.plot_heatmap(matrix, f"{method} Heatmap", legend_text=f"Lag={lag}")
+                    st.image(heatmap, caption=method)
 
             st.subheader("Connectome")
             primary_method = resolved_methods[0]
-            matrix = compute_connectivity_variant(
-                tool.data_normalized,
-                primary_method,
-                lag=lag,
-            )
+            matrix = tool_mod.compute_connectivity_variant(engine.data_normalized, primary_method, lag=lag)
             directed = "directed" in primary_method or "partial" in primary_method
             invert = "granger" in primary_method
-            connectome = plot_connectome(
+            connectome = tool_mod.plot_connectome(
                 matrix,
                 f"{primary_method} Connectome",
                 threshold=threshold,
                 directed=directed,
                 invert_threshold=invert,
                 legend_text=f"Lag={lag}",
             )
             st.image(connectome, caption=primary_method)
 
-            with open(output_path, "rb") as f:
-                st.download_button(
-                    "Download Excel",
-                    data=f.read(),
-                    file_name="AllMethods_Full.xlsx",
-                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
-                )
+            st.subheader("Full report (local CLI)")
+            st.code(
+                f"python cli.py {uploaded_file.name} --lags {int(lag)} --graph-threshold {float(threshold)}",
+                language="bash",
+            )
+            st.caption("Полный Excel (с листами, графиками, окнами) генерируй локально — в облаке это слишком тяжело.")
 
 
 if __name__ == "__main__":
     main()
diff --git a/huinya-main/tool.py b/tool.py
similarity index 98%
rename from huinya-main/tool.py
rename to tool.py
index 8ef8a8b..4e3cf37 100644
--- a/huinya-main/tool.py
+++ b/tool.py
@@ -1,14 +1,19 @@
 #!/usr/bin/env python3
 # -*- coding: utf-8 -*-
 
 import argparse
 import importlib
 import importlib.util
 import logging
 import os
 import warnings
 from io import BytesIO
 from itertools import chain, combinations, permutations
 from typing import List, Optional
 
 import matplotlib
-matplotlib.use('Agg')
+"""
+Важное: в Streamlit Cloud cold start может падать, если мы делаем лишнее при импорте.
+Agg оставляем (нужен для headless), но избегаем любого "тяжёлого" выполнения на import-time.
+"""
+matplotlib.use("Agg")
 import matplotlib.pyplot as plt
 import networkx as nx
 import nolds
 import numpy as np
 import pandas as pd
@@ -34,6 +39,10 @@ from statsmodels.tsa.stattools import adfuller, grangercausalitytests
 from statsmodels.tsa.vector_ar.var_model import VAR
 from tqdm import tqdm
 
+"""
+Остальной файл без изменений по логике.
+Полный отчёт (export_big_excel) предполагается запускать локально через cli.py.
+"""
 
 def configure_warnings(quiet: bool = False) -> None:
     """Настраивает предупреждения без глобального подавления."""
diff --git a/huinya-main/requirements.txt b/requirements.txt
similarity index 100%
rename from huinya-main/requirements.txt
rename to requirements.txt
diff --git a/README.md b/README.md
index 0f3c0a1..f9c1db2 100644
--- a/README.md
+++ b/README.md
@@ -1 +1,70 @@
-# huinya-main
+# Time Series Connectivity Toolkit
+
+Два режима:
+
+1) **Streamlit demo (Cloud/локально):** быстрые heatmap/connectome (без тяжёлого full Excel).
+2) **Полный отчёт (локально, CLI):** генерация `AllMethods_Full.xlsx` со всеми листами/картинками.
+
+## Streamlit (demo)
+
+Локально:
+
+```bash
+pip install -r requirements.txt
+streamlit run app.py
+```
+
+В облаке (Streamlit Cloud): стартует быстро, потому что не делает полный `export_big_excel`.
+
+## CLI (полный Excel отчёт)
+
+```bash
+pip install -r requirements.txt
+python cli.py demo.csv --lags 5 --graph-threshold 0.5
+```
+
+На выходе будет `AllMethods_Full.xlsx` (по умолчанию в текущей директории или в указанном `--output`).
+
diff --git a/cli.py b/cli.py
new file mode 100644
index 0000000..c6c0ae2
--- /dev/null
+++ b/cli.py
@@ -0,0 +1,124 @@
+#!/usr/bin/env python3
+# -*- coding: utf-8 -*-
+
+"""
+CLI entrypoint for FULL report generation (heavy).
+
+Зачем отдельный файл:
+- Streamlit Cloud не должен генерить гигантский Excel с картинками (таймаут/память).
+- Локально CLI спокойно делает полный export.
+"""
+
+from __future__ import annotations
+
+import argparse
+import logging
+import os
+
+from tool import BigMasterTool, configure_warnings, method_mapping, save_folder
+
+
+def build_parser() -> argparse.ArgumentParser:
+    p = argparse.ArgumentParser(description="Compute connectivity measures for multivariate time series.")
+    p.add_argument("input_file", help="Path to input CSV or Excel file with time series data")
+    p.add_argument("--lags", type=int, default=5, help="Max lag/model order (for Granger, TE, etc.)")
+    p.add_argument("--log", action="store_true", help="Apply logarithm transform to data (for positive-valued data)")
+    p.add_argument("--no-outliers", action="store_true", help="Disable outlier removal")
+    p.add_argument("--no-normalize", action="store_true", help="Disable normalization of data")
+    p.add_argument("--no-stationarity-check", action="store_true", help="Disable stationarity check (ADF test)")
+    p.add_argument("--graph-threshold", type=float, default=0.5, help="Threshold for graph edges")
+    p.add_argument("--output", default=None, help="Output Excel file path (default: TimeSeriesAnalysis/AllMethods_Full.xlsx)")
+    p.add_argument("--quiet-warnings", action="store_true", help="Suppress most warnings for cleaner CLI output")
+    p.add_argument("--experimental", action="store_true", help="Enable experimental sliding-window analyses")
+    return p
+
+
+def main() -> None:
+    args = build_parser().parse_args()
+
+    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
+    configure_warnings(quiet=args.quiet_warnings)
+
+    filepath = os.path.abspath(args.input_file)
+    output_path = args.output or os.path.join(save_folder, "AllMethods_Full.xlsx")
+    output_dir = os.path.dirname(output_path)
+    if output_dir:
+        os.makedirs(output_dir, exist_ok=True)
+
+    tool = BigMasterTool(enable_experimental=args.experimental)
+    tool.lag_ranges = {v: range(1, args.lags + 1) for v in method_mapping}
+
+    tool.load_data_excel(
+        filepath,
+        log_transform=args.log,
+        remove_outliers=not args.no_outliers,
+        normalize=not args.no_normalize,
+        fill_missing=True,
+        check_stationarity=not args.no_stationarity_check,
+    )
+    tool.run_all_methods()
+    tool.export_big_excel(
+        output_path,
+        threshold=args.graph_threshold,
+        window_size=100,
+        overlap=50,
+        log_transform=args.log,
+        remove_outliers=not args.no_outliers,
+        normalize=not args.no_normalize,
+        fill_missing=True,
+        check_stationarity=not args.no_stationarity_check,
+    )
+
+    print("Готово. Excel сохранён в:", output_path)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/huinya-main/demo.csv b/demo.csv
similarity index 100%
rename from huinya-main/demo.csv
rename to demo.csv
diff --git a/huinya-main/demo_output.xlsx b/demo_output.xlsx
similarity index 100%
rename from huinya-main/demo_output.xlsx
rename to demo_output.xlsx
diff --git a/huinya-main/README.md b/huinya-main/README.md
deleted file mode 100644
index 0f3c0a1..0000000
--- a/huinya-main/README.md
+++ /dev/null
@@ -1 +0,0 @@
-# huinya-main
